{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buy_items() function\n",
    "\n",
    "starting_money = 100\n",
    "starting_num_items = 10\n",
    "item_price = 4\n",
    "\n",
    "# Your code here\n",
    "def buy_items(money,stock,price):\n",
    "  num_bought =0\n",
    "  while stock>0:\n",
    "    money-=price\n",
    "    num_bought+=1\n",
    "    stock-=1\n",
    "    if money<price:\n",
    "      break\n",
    "  return num_bought\n",
    "\n",
    "total = buy_items(starting_money, starting_num_items, item_price)\n",
    "print(\"You were able to buy \" + str(total) + \" items.\")\n",
    "  \n",
    "# For testing purposes\n",
    "total_1 = buy_items(100, 10, 4)\n",
    "print(\"Test 1: \" + str(total_1))\n",
    "total_2 = buy_items(10, 10, 4)\n",
    "print(\"Test 2: \" + str(total_2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_scores = {\"Gina\":[80, 72, 90], \"Javed\":[88, 68, 81], \"Siobhan\":[80, 82, 84], \"Pedro\":[98, 96, 95], \"Marcel\":[78, 80, 78], \"Dilip\":[64, 60, 75]}\n",
    "\n",
    "## Modify dictionary\n",
    "for score in test_scores.values():\n",
    "  score[0]+=1\n",
    "\n",
    "## Write to a text file\n",
    "with open('modified_scores.txt', 'w') as f:\n",
    "    f.write(str(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load Dataset\n",
    "movie_ratings=pd.read_csv(\"movie_ratings.csv\")\n",
    "#Print number of unique users who rated the movies\n",
    "print(movie_ratings.userId.nunique())\n",
    "\n",
    "# Lambda, calculate dataframe row mean\n",
    "\n",
    "import pandas as pd\n",
    "df1 = pd.DataFrame({'Fruit': [\"guava\",\"apple\",\"orange\", \"mango\"], 'A': [4,1,3,2],'B': [5,3,1,1]})\n",
    "df2 = pd.DataFrame({'Fruit': [\"guava\",\"apple\",\"honeydew\",\"orange\", \"mango\"],'E': [4,2,5,1,2],'C': [3,5,2,1,1],\n",
    "'D': [4,3,5,3,3]})\n",
    "\n",
    "df=df1.merge(df2,how=\"inner\",on=\"Fruit\")\n",
    "df[\"mean_rating\"]=df.drop('Fruit', axis=1).apply(lambda x:x.mean(),axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  buying  maint doors persons lug_boot safety  accep\n",
      "0  vhigh  vhigh     2       2    small    low  unacc\n",
      "1  vhigh  vhigh     2       2    small    med  unacc\n",
      "2  vhigh  vhigh     2       2    small   high  unacc\n",
      "3  vhigh  vhigh     2       2      med    low  unacc\n",
      "4  vhigh  vhigh     2       2      med    med  unacc\n",
      "['2' '2' '2' ... '5more' '5more' '5more']\n",
      "0.7002314814814815\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', \n",
    "names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'accep'])\n",
    "\n",
    "print(df.head())\n",
    "test=df.doors.values\n",
    "print(test)\n",
    "\n",
    "# No. of fields that are categorical variables (cat_fields_no)\n",
    "\n",
    "cat_fields_no=5\n",
    "\n",
    "# Fraction of cars that are not acceptable (frac_unacc)\n",
    "\n",
    "frac_unacc=len(df[df[\"accep\"]==\"unacc\"])/len(df)\n",
    "\n",
    "print(frac_unacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contingency table, Chi Square\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'accep'])\n",
    "\n",
    "# Print contingency table for 'safety' and 'accep'\n",
    "\n",
    "table1 = pd.crosstab(df.safety, df.accep)\n",
    "print(table1)\n",
    "\n",
    "# Value of 'safety' corresponding to highest frequency for 'unacc'\n",
    "\n",
    "highest_freq_unacc=\"low\"\n",
    "\n",
    "\n",
    "# Calculate chi-square statistic for association between 'safety' and 'accep'\n",
    "chi2, pval1, dof, expected = chi2_contingency(table1)\n",
    "print(format(pval1,'f'))\n",
    "\n",
    "chi2_safety=chi2\n",
    "print(chi2_safety)\n",
    "\n",
    "# Calculate chi-square statistic for association between 'doors' and 'accep'\n",
    "table2 = pd.crosstab(df.doors, df.accep)\n",
    "\n",
    "chi22, pval2, dof, expected = chi2_contingency(table2)\n",
    "print(chi22)\n",
    "\n",
    "chi2_doors=chi22\n",
    "\n",
    "#Which variable has a higher association with 'accep'?\n",
    "\n",
    "higher_association=\"safety\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear regression\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# load data\n",
    "coffee = pd.read_csv('coffee.csv')\n",
    "print(coffee.head())\n",
    "#run and fit the model\n",
    "model = sm.OLS.from_formula('sales ~ temp', data = coffee)\n",
    "results = model.fit()\n",
    "# print the model params\n",
    "print(results.params)\n",
    "\n",
    "# calculate `pred_75`\n",
    "new_data={\"temp\":[75]}\n",
    "pred_75=results.predict(new_data)\n",
    "print(pred_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Sample T-Test\n",
    "#evaluate if mean is the same as population mean\n",
    "\n",
    "from scipy.stats import ttest_1samp\n",
    "import numpy as np\n",
    "\n",
    "prices = np.genfromtxt(\"prices.csv\")\n",
    "print(prices)\n",
    "\n",
    "prices_mean = np.mean(prices)\n",
    "print(\"mean of prices: \" + str(prices_mean))\n",
    "\n",
    "# use ttest_1samp to calculate pval\n",
    "tstat, pval = ttest_1samp(prices, 1000)\n",
    "# print pval\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a pie chart\n",
    "import pandas as pd\n",
    "import codecademylib3\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"co2_emissions.csv\")\n",
    "print(df)\n",
    "\n",
    "#Calulate proportion of total emissions contributed by each emission source\n",
    "df['prop'] = df['emissions']/df['emissions'].sum()\n",
    "wedge_sizes = df['prop']\n",
    "\n",
    "plt.pie(wedge_sizes,labels=df.source)\n",
    "plt.axis('equal')\n",
    "plt.title('Distribution of CO2 Emissions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a line chart\n",
    "import pandas as pd\n",
    "import codecademylib3\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"annual-co-emissions-by-region.csv\")\n",
    "# print(df.head())\n",
    "\n",
    "#Create DataFrame df_USA\n",
    "\n",
    "df_USA=df[df[\"Entity\"]=='United States']\n",
    "print(df_USA)\n",
    "#Create line plot\n",
    "fig = plt.gca()\n",
    "plt.plot(df_USA[\"Year\"],df_USA[\"Annual COâ‚‚ emissions (zero filled)\"])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('CO2 emission')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a histogram\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import codecademylib3\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('candy-data.csv')\n",
    "print(df.head())\n",
    "# Save `winpercent` values to a separate numpy array, win_values\n",
    "win_values=np.array(df.winpercent)\n",
    "# Use plt.hist() to plot a histogram with 5 bins\n",
    "plt.hist(win_values,bins=5)\n",
    "plt.xlabel(\"Win Values\")\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign numeric value to categorical variables\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('fraud_data.csv')\n",
    "print(df.head())\n",
    "\n",
    "#Define and print browser_counts\n",
    "browser_counts=df.browser.value_counts()\n",
    "browsers=df.browser.unique()\n",
    "print(browser_counts)\n",
    "\n",
    "#Convert 'browser' to a categorical variable type\n",
    "df['browser'] = pd.Categorical(df['browser'], browsers)\n",
    "\n",
    "#Median browser value\n",
    "median_browser_used = np.median(df['browser'].cat.codes)\n",
    "print(median_browser_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('fraud_data.csv')\n",
    "#print(df.head())\n",
    "\n",
    "#minimum and maximum age values\n",
    "min_age=df.age.min()\n",
    "max_age=df.age.max()\n",
    "print(min_age)\n",
    "print(max_age)\n",
    "\n",
    "#Binning 'age' column\n",
    "bins = [10,20,30,40,50,60,70,80]\n",
    "\n",
    "#Counts of users falling in the different age ranges\n",
    "df[\"age\"]=pd.cut(df[\"age\"],bins=bins,)\n",
    "age_range_counts=df.age.value_counts()\n",
    "print(age_range_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacked bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"]\n",
    "video_game_hours = [1, 2, 2, 1, 2]\n",
    "book_hours = [2, 3, 4, 2, 1]\n",
    "\n",
    "plt.bar(range(len(video_game_hours)),video_game_hours) \n",
    "plt.bar(range(len(book_hours)),book_hours, bottom=video_game_hours)\n",
    "plt.xticks(ticks = [1,2,3,4,5], labels = days)\n",
    "plt.legend([\"Video Games\", \"Books\"])\n",
    "plt.title(\"Breakdown of Entertainment Hours\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# load in data\n",
    "sales_data = pd.read_csv(\"sales_data.csv\")\n",
    "\n",
    "# calculate total sales for each month\n",
    "sales = sales_data.groupby([\"year\", \"month\"]).sum()\n",
    "\n",
    "# re-format the data for the heat-map\n",
    "sales_month_year = sales.reset_index().pivot(index=\"year\", columns=\"month\", values=\"sales\")\n",
    "\n",
    "# create heatmap\n",
    "sns.heatmap(sales_month_year, cbar_kws={\"label\": \"Total Sales\"})\n",
    "plt.title(\"Sales Over Time\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Year\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
